{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037795a4",
   "metadata": {},
   "source": [
    "### That's the first script after pre-processing with R \n",
    "\n",
    "#### Train-val-test splits are already provided in csv files, so this script only creates the required .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb3b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle \n",
    "np.random.seed(1234)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9474794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../Data/miiv_fullstays\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd5eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ts_data_mask.csv', 'static_data_scaled.csv', 'ts_data_scaled.csv', 'admissions.csv']\n"
     ]
    }
   ],
   "source": [
    "load_path = \"../load_ICU_datasets/miiv/\"\n",
    "print(os.listdir(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c65656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all csv files \n",
    "df_adm = pd.read_csv(os.path.join(load_path, \"admissions.csv\"))\n",
    "df_ts = pd.read_csv(os.path.join(load_path, \"ts_data_scaled.csv\"))\n",
    "df_ts_mask = pd.read_csv(os.path.join(load_path, \"ts_data_mask.csv\"))\n",
    "df_static = pd.read_csv(os.path.join(load_path, \"static_data_scaled.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7757a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm.set_index(\"stay_id\", inplace=True)\n",
    "df_static.set_index(\"stay_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99f1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get train-val-test ids from admissions table\n",
    "train_ids = df_adm[df_adm.splitType == \"train\"].index.values\n",
    "val_ids = df_adm[df_adm.splitType == \"val\"].index.values\n",
    "test_ids = df_adm[df_adm.splitType == \"test\"].index.values\n",
    "\n",
    "#Shuffle indices \n",
    "np.random.shuffle(train_ids)\n",
    "np.random.shuffle(val_ids)\n",
    "np.random.shuffle(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc65bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with mortality labels\n",
    "mortality_train = df_adm.loc[train_ids].hospital_expire_flag.values\n",
    "mortality_val = df_adm.loc[val_ids].hospital_expire_flag.values\n",
    "mortality_test = df_adm.loc[test_ids].hospital_expire_flag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f8676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_static_features(enc, df, split_ids):\n",
    "    \"\"\"\n",
    "    This function takes all features until adm_categ as usual, then appends one-hot-encoded adm_categ and \n",
    "    finally appends the rest of the features\n",
    "    \"\"\"\n",
    "    col_index_adm = np.where(df_static.columns == \"adm_categ\")[0][0]\n",
    "    \n",
    "    subset_df = df.loc[split_ids]\n",
    "    \n",
    "    before_adm = subset_df.iloc[:,:col_index_adm].values\n",
    "    after_adm = subset_df.iloc[:,(col_index_adm+1):].values\n",
    "    \n",
    "    adm_categ = subset_df.adm_categ.values.reshape(-1,1)\n",
    "    adm_onehot = enc.transform(adm_categ).toarray()\n",
    "    \n",
    "    all_static_features = np.c_[before_adm, adm_onehot, after_adm]\n",
    "    return all_static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6b21a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Static Features \n",
    "\n",
    "#We will one-hot-encode admissiontype\n",
    "adm_encoder = OneHotEncoder()\n",
    "max_adm_type = df_static.adm_categ.max()\n",
    "adm_encoder.fit(np.arange(max_adm_type+1).reshape(-1,1))\n",
    "\n",
    "static_train = organize_static_features(adm_encoder, df_static, train_ids)\n",
    "static_val = organize_static_features(adm_encoder, df_static, val_ids)\n",
    "static_test = organize_static_features(adm_encoder, df_static, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "500c98eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34546/34546 [02:16<00:00, 252.41it/s]\n",
      "/local/home/oezyurty/cl_icu/lib/python3.6/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n",
      "100%|██████████| 7403/7403 [00:29<00:00, 254.31it/s]\n",
      "/local/home/oezyurty/cl_icu/lib/python3.6/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n",
      "100%|██████████| 7402/7402 [00:26<00:00, 276.69it/s]\n",
      "/local/home/oezyurty/cl_icu/lib/python3.6/site-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#Time series features\n",
    "timeseries_train = []\n",
    "for id_ in tqdm(train_ids):\n",
    "    timeseries_id = df_ts[df_ts.stay_id == id_].sort_values(by=\"charttime\").iloc[:,2:].values\n",
    "    timeseries_train.append(timeseries_id)\n",
    "timeseries_train = np.array(timeseries_train)\n",
    "\n",
    "timeseries_val = []\n",
    "for id_ in tqdm(val_ids):\n",
    "    timeseries_id = df_ts[df_ts.stay_id == id_].sort_values(by=\"charttime\").iloc[:,2:].values\n",
    "    timeseries_val.append(timeseries_id)\n",
    "timeseries_val = np.array(timeseries_val)\n",
    "\n",
    "timeseries_test = []\n",
    "for id_ in tqdm(test_ids):\n",
    "    timeseries_id = df_ts[df_ts.stay_id == id_].sort_values(by=\"charttime\").iloc[:,2:].values\n",
    "    timeseries_test.append(timeseries_id)\n",
    "timeseries_test = np.array(timeseries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ee956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/oezyurty/cl_icu/lib/python3.6/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n",
      "/local/home/oezyurty/cl_icu/lib/python3.6/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == '':\n",
      "/local/home/oezyurty/cl_icu/lib/python3.6/site-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "#Time series masks\n",
    "timeseries_train_mask = []\n",
    "for id_ in train_ids:\n",
    "    timeseries_id = df_ts_mask[df_ts_mask.stay_id == id_].sort_values(by=\"charttime\").iloc[:,2:].values\n",
    "    timeseries_train_mask.append(timeseries_id)\n",
    "timeseries_train_mask = np.array(timeseries_train_mask)\n",
    "\n",
    "timeseries_val_mask = []\n",
    "for id_ in val_ids:\n",
    "    timeseries_id = df_ts_mask[df_ts_mask.stay_id == id_].sort_values(by=\"charttime\").iloc[:,2:].values\n",
    "    timeseries_val_mask.append(timeseries_id)\n",
    "timeseries_val_mask = np.array(timeseries_val_mask)\n",
    "\n",
    "timeseries_test_mask = []\n",
    "for id_ in test_ids:\n",
    "    timeseries_id = df_ts_mask[df_ts_mask.stay_id == id_].sort_values(by=\"charttime\").iloc[:,2:].values\n",
    "    timeseries_test_mask.append(timeseries_id)\n",
    "timeseries_test_mask = np.array(timeseries_test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a36969d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE ALL THE NUMPY ARRAYS\n",
    "\n",
    "np.save(os.path.join(save_path, \"mortality_train.npy\"), mortality_train)\n",
    "np.save(os.path.join(save_path, \"mortality_val.npy\"), mortality_val)\n",
    "np.save(os.path.join(save_path, \"mortality_test.npy\"), mortality_test)\n",
    "\n",
    "np.save(os.path.join(save_path, \"static_train.npy\"), static_train)\n",
    "np.save(os.path.join(save_path, \"static_val.npy\"), static_val)\n",
    "np.save(os.path.join(save_path, \"static_test.npy\"), static_test)\n",
    "\n",
    "np.save(os.path.join(save_path, \"timeseries_train.npy\"), timeseries_train)\n",
    "np.save(os.path.join(save_path, \"timeseries_val.npy\"), timeseries_val)\n",
    "np.save(os.path.join(save_path, \"timeseries_test.npy\"), timeseries_test)\n",
    "\n",
    "np.save(os.path.join(save_path, \"timeseries_train_mask.npy\"), timeseries_train_mask)\n",
    "np.save(os.path.join(save_path, \"timeseries_val_mask.npy\"), timeseries_val_mask)\n",
    "np.save(os.path.join(save_path, \"timeseries_test_mask.npy\"), timeseries_test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46fe0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_splits = dict()\n",
    "dict_splits[\"train\"] = train_ids\n",
    "dict_splits[\"val\"] = val_ids\n",
    "dict_splits[\"test\"] = test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d41f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(save_path, \"split_stay_ids.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(dict_splits, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
